{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import platform\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.datasets as datasets\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_width = 224\n",
    "transform=transforms.ToTensor()\n",
    "def process_img(image):\n",
    "    desired_length = int(desired_width * (image.size[0]/image.size[1]))\n",
    "    new=image.resize((desired_width, desired_width))\n",
    "    back = Image.new(\"L\", (224, 224))  \n",
    "    back.paste(new)\n",
    "    img=transform(back)\n",
    "    new.close()\n",
    "    back.close()\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH=\"../chest-xray-pneumonia/chest_xray/chest_xray/\"\n",
    "def load_data(dataset):\n",
    "    path=FILE_PATH+dataset+\"/\"\n",
    "    data=[]\n",
    "    for file in os.listdir(path+\"PNEUMONIA/\"):\n",
    "        if not(file.startswith('.')):\n",
    "            img=Image.open(path+\"PNEUMONIA/\"+file)\n",
    "            temp=[]\n",
    "            temp.append(process_img(img.convert(\"L\")))\n",
    "            temp.append(1)\n",
    "            data.append(temp)\n",
    "            img.close()\n",
    "    for file in os.listdir(path+\"NORMAL/\"):\n",
    "        if not(file.startswith('.')):\n",
    "            img=Image.open(path+\"NORMAL/\"+file)\n",
    "            temp=[]\n",
    "            temp.append(process_img(img.convert(\"L\")))\n",
    "            temp.append(0)\n",
    "            data.append(temp)\n",
    "            img.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set=load_data(\"train\")\n",
    "test_set=load_data(\"test\")\n",
    "val_set=load_data(\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0706, 0.0824, 0.1059,  ..., 0.0314, 0.0078, 0.0039],\n",
       "         [0.0745, 0.0941, 0.1059,  ..., 0.0353, 0.0196, 0.0039],\n",
       "         [0.0863, 0.0941, 0.0980,  ..., 0.0392, 0.0235, 0.0039],\n",
       "         ...,\n",
       "         [0.0392, 0.0392, 0.0353,  ..., 0.0588, 0.0588, 0.0588],\n",
       "         [0.0392, 0.0392, 0.0392,  ..., 0.0588, 0.0588, 0.0588],\n",
       "         [0.0392, 0.0392, 0.0392,  ..., 0.0588, 0.0588, 0.0588]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.cl1=nn.Conv2d(1,12,kernel_size=3)\n",
    "        self.mp1=nn.MaxPool2d(2)\n",
    "        self.cl2=nn.Conv2d(12,3,kernel_size=3)\n",
    "        self.mp2=nn.MaxPool2d(2)\n",
    "        self.fcl=nn.Linear(8748,2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # x dim: b x 800 x 600 x 3 -> b x 1 x 100 x 100\n",
    "        out=F.relu(self.cl1(x)) # b x 18 x whatever x whatever\n",
    "        out=self.mp1(out)\n",
    "        out=F.relu(self.cl2(out))\n",
    "        out=self.mp2(out)\n",
    "        \n",
    "        # at this point, we should have a tensor that's b x inchannels x 1 x 1\n",
    "        out=out.view(out.size(0),-1)\n",
    "#         print(out.shape)\n",
    "        out=F.sigmoid(self.fcl(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=CNN()\n",
    "model.eval()\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.001,weight_decay=0.00001)\n",
    "criterion=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch,model,train_loader,optimizer):\n",
    "    model.train()\n",
    "    \n",
    "    total_loss=0\n",
    "    correct=0\n",
    "    \n",
    "    for i, (image,label) in enumerate(train_loader):\n",
    "        \n",
    "        #print(i)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "#         print(label.shape)\n",
    "       \n",
    "        \n",
    "        prediction=model(image)\n",
    "        \n",
    "        loss=criterion(prediction,label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss+=loss\n",
    "        \n",
    "        pred_classes=prediction.data.max(1,keepdim=True)[1]\n",
    "        \n",
    "        correct+=pred_classes.eq(label.data.view_as(pred_classes)).sum().double()\n",
    "        \n",
    "    mean_loss=total_loss/len(train_loader.dataset)\n",
    "    acc=correct/len(train_loader.dataset)\n",
    "    \n",
    "    print('Train Epoch: {}   Avg_Loss: {:.5f}   Acc: {}/{} ({:.3f}%)'.format(\n",
    "        epoch, mean_loss, correct, len(train_loader.dataset),\n",
    "        100. * acc))\n",
    "\n",
    "    return mean_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model,test_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    total_loss=0\n",
    "    correct=0\n",
    "    \n",
    "    for i, (image,label) in enumerate(test_loader):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        prediction=model(image)\n",
    "        \n",
    "        loss=criterion(prediction,label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss+=loss\n",
    "        \n",
    "        pred_classes=prediction.data.max(1,keepdim=True)[1]\n",
    "        \n",
    "        correct+=pred_classes.eq(label.data.view_as(pred_classes)).sum().double()\n",
    "        \n",
    "    mean_loss=total_loss/len(test_loader.dataset)\n",
    "    \n",
    "    acc=correct/len(test_loader.dataset)\n",
    "    \n",
    "    print('Eval:   Avg_Loss: {:.5f}   Acc: {}/{} ({:.3f}%)'.format(\n",
    "         mean_loss, correct, len(test_loader.dataset),\n",
    "        100. * acc))\n",
    "\n",
    "    return mean_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(epoch, model, path='./'):\n",
    "    \n",
    "    # file name and path \n",
    "    filename = path + 'chestXRay_{}.pt'.format(epoch)\n",
    "    \n",
    "    # load the model parameters \n",
    "    torch.save(model.state_dict(), filename)\n",
    "    \n",
    "    \n",
    "    return model\n",
    "\n",
    "def load_model(epoch, model, path='./'):\n",
    "    \n",
    "    # file name and path \n",
    "    filename = path + 'chestXRay_{}.pt'.format(epoch)\n",
    "    \n",
    "    # load the model parameters \n",
    "    model.load_state_dict(torch.load(filename))\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=32\n",
    "train_loader=data.DataLoader(train_set,batch_size=BATCH_SIZE,shuffle=True)\n",
    "valid_loader=data.DataLoader(val_set,batch_size=BATCH_SIZE,shuffle=True)\n",
    "test_loader=data.DataLoader(test_set,batch_size=BATCH_SIZE,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x17584cae080>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaylee\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1   Avg_Loss: 0.01652   Acc: 4002.0/5216 (76.725%)\n",
      "Eval:   Avg_Loss: 0.01494   Acc: 534.0/624 (85.577%)\n",
      "Train Epoch: 2   Avg_Loss: 0.01147   Acc: 4948.0/5216 (94.862%)\n",
      "Eval:   Avg_Loss: 0.01417   Acc: 540.0/624 (86.538%)\n",
      "Train Epoch: 3   Avg_Loss: 0.01103   Acc: 5017.0/5216 (96.185%)\n",
      "Eval:   Avg_Loss: 0.01362   Acc: 555.0/624 (88.942%)\n",
      "Train Epoch: 4   Avg_Loss: 0.01095   Acc: 5019.0/5216 (96.223%)\n",
      "Eval:   Avg_Loss: 0.01493   Acc: 518.0/624 (83.013%)\n",
      "Train Epoch: 5   Avg_Loss: 0.01087   Acc: 5036.0/5216 (96.549%)\n",
      "Eval:   Avg_Loss: 0.01354   Acc: 552.0/624 (88.462%)\n"
     ]
    }
   ],
   "source": [
    "num_epoch=10\n",
    "checkpoint_freq=5\n",
    "path=\"./\"\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# traininng \n",
    "for epoch in range(1, num_epoch + 1):\n",
    "    \n",
    "    # train() function (see above)\n",
    "    train_loss, train_acc = train(epoch, model, train_loader, optimizer)\n",
    "    \n",
    "    # eval() functionn (see above)\n",
    "    test_loss, test_acc = eval(model, test_loader)    \n",
    "    \n",
    "    # append lists for plotting and printing \n",
    "    train_losses.append(train_loss)    \n",
    "    test_losses.append(test_loss)\n",
    "    \n",
    "    train_accuracies.append(train_acc)    \n",
    "    test_accuracies.append(test_acc)\n",
    "    \n",
    "    # Checkpoint\n",
    "    if epoch % checkpoint_freq ==0:\n",
    "        save_model(epoch, model, path)\n",
    "\n",
    "# Last checkpoint\n",
    "save_model(num_epoch, model, path)\n",
    "    \n",
    "print(\"\\n\\n\\nOptimization ended.\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn=CNN()\n",
    "cnn=load_model(10,cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "losses=[]\n",
    "total_loss=0\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "for i,(image,label) in enumerate (val_set):\n",
    "#     print(image.shape)\n",
    "    predictio=cnn(image.unsqueeze(0))\n",
    "    loss=criterion(prediction,label)\n",
    "    losses.append(loss)\n",
    "    total_loss+=loss\n",
    "avg_loss=total_loss/len(val_set.dataset)\n",
    "print(avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses,color='darkcyan')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " @app.route('/manage_game', methods=['POST'])\n",
    "    import cgi\n",
    "    form = cgi.FieldStorage()\n",
    "    upload_img =  form.getvalue('pic')\n",
    "     \n",
    "    desired_width = 224\n",
    "    transform=transforms.ToTensor()\n",
    "\n",
    "    desired_length = int(desired_width * (upload_img.size[0]/upload_img.size[1]))\n",
    "    new=upload_img.resize((desired_width, desired_width))\n",
    "    back = Image.new(\"L\", (224, 224))  \n",
    "    back.paste(new)\n",
    "    img=transform(back)\n",
    "    new.close()\n",
    "    back.close()\n",
    "    \n",
    "    prediction = model(img)\n",
    "    \n",
    "    print(prediction)\n",
    "    \n",
    "#     print(\"\"\"\n",
    "#     <!DOCTYPE html>\n",
    "#     <html>\n",
    "#     <head>\n",
    "#         <title>Page Title</title>\n",
    "#         <link rel=\"stylesheet\" href=\"demo.css\">\n",
    "#     </head>\n",
    "\n",
    "#     <body>\n",
    "\n",
    "#     <div class=\"head-part\">\n",
    "#         <div class=\"head-word\">\n",
    "#             <div class=\"header\">\n",
    "#                 <p>Pneumonia Detector <span>Demo</span></p>\n",
    "#             </div>\n",
    "#             <divss class=\"description\">\n",
    "#                 <p>An easy-used, reliable tool to help identify whether the lung\n",
    "#                     has pneumonia, with simply one uploaded chest x-ray.</p>\n",
    "#             </divss>\n",
    "#         </div>\n",
    "\n",
    "\n",
    "#     </div>\n",
    "\n",
    "#       \"\"\")\n",
    "          \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
